Metadata-Version: 2.4
Name: chatbot-service
Version: 0.1.0
Summary: Secure FastAPI gateway for Vertex AI chatbot deployments
Author-email: Platform Team <platform@example.com>
License: Apache-2.0
Requires-Python: >=3.10
Description-Content-Type: text/markdown
Requires-Dist: fastapi<0.112,>=0.110
Requires-Dist: uvicorn[standard]<0.30,>=0.24
Requires-Dist: pydantic<3.0,>=2.5
Requires-Dist: pydantic-settings<3.0,>=2.2
Requires-Dist: python-dotenv<2.0,>=1.0
Requires-Dist: google-cloud-aiplatform<2.0,>=1.38
Requires-Dist: google-cloud-logging<4.0,>=3.6
Requires-Dist: google-auth<3.0,>=2.23
Requires-Dist: httpx<0.28,>=0.25
Provides-Extra: dev
Requires-Dist: pytest<8.0,>=7.4; extra == "dev"
Requires-Dist: pytest-asyncio<0.24,>=0.21; extra == "dev"
Requires-Dist: pytest-cov<5.0,>=4.1; extra == "dev"
Requires-Dist: ruff<0.6.0,>=0.3.0; extra == "dev"
Requires-Dist: mypy<1.9,>=1.6; extra == "dev"

ï»¿# Chatbot Service

FastAPI application acting as the secure entry point for the Vertex AI powered chatbot workflow. It enforces authentication, applies rate limits, and records audit trails while providing an offline stub for local development.

## Quickstart
1. Create a virtual environment: `python -m venv .venv && .venv\Scripts\activate` (Windows) or `source .venv/bin/activate` (Linux/macOS).
2. Install dependencies: `pip install -e .[dev]`.
3. Run tests: `pytest`.
4. Start the API locally: `uvicorn chatbot_service.main:app --reload`.

Environment variables (or `.env` file) control integration with GCP resources. Set `OFFLINE_MODE=true` to bypass Vertex AI calls when running locally.

## Container Image
Build and run the production image with Docker:
```bash
# from the repository root
cd app
docker build -t chatbot-service:latest .
docker run -p 8080:8080 --env-file .env.example chatbot-service:latest
```
The GitHub Actions deploy workflow uses `gcloud builds submit app` to build this Dockerfile automatically before rolling out to Cloud Run.
